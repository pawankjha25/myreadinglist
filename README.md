**July Reading list**

2014â€“2017: Foundations of Generative Models

1. Generative Adversarial Nets (GANs)
Ian Goodfellow et al., 2014
ðŸ”¹ Introduced adversarial learning framework.
ðŸ”¹ Kickstarted a whole field of generative modeling.

ðŸ“Œ Citation: https://arxiv.org/abs/1406.2661

2. Auto-Encoding Variational Bayes (VAE)
Kingma & Welling, 2014
ðŸ”¹ Introduced the Variational Autoencoder (VAE).
ðŸ”¹ Key technique in probabilistic generative modeling.

ðŸ“Œ Citation: https://arxiv.org/abs/1312.6114

3. Pixel Recurrent Neural Networks
van den Oord et al., 2016
ðŸ”¹ Introduced autoregressive models for images.
ðŸ”¹ Basis for PixelCNN, PixelRNN.

ðŸ“Œ Citation: https://arxiv.org/abs/1601.06759

4. WaveNet: A Generative Model for Raw Audio
van den Oord et al., DeepMind, 2016
ðŸ”¹ High-quality speech generation.
ðŸ”¹ Basis for audio models and later neural codecs.

ðŸ“Œ Citation: https://arxiv.org/abs/1609.03499

ðŸ§  2018â€“2020: Rise of Transformers and Language Generation
5. Attention is All You Need
Vaswani et al., 2017
ðŸ”¹ Introduced the Transformer architecture.
ðŸ”¹ Foundation for all LLMs and multimodal transformers.

ðŸ“Œ Citation: https://arxiv.org/abs/1706.03762

6. BERT: Pre-training of Deep Bidirectional Transformers
Devlin et al., 2018 (Google AI)
ðŸ”¹ Masked language modeling + fine-tuning.
ðŸ”¹ Not generative per se, but a turning point in transformer-based modeling.

ðŸ“Œ Citation: https://arxiv.org/abs/1810.04805

7. GPT-2: Language Models are Unsupervised Multitask Learners
OpenAI, 2019
ðŸ”¹ Showed impressive few-shot/few-label performance.
ðŸ”¹ Marked the beginning of generative LLMs with practical value.

ðŸ“Œ Blog: https://openai.com/research/language-unsupervised

8. Taming Transformers for High-Resolution Image Synthesis
Esser et al., 2020 (VQ-VAE-2 + Transformers)
ðŸ”¹ Combined vector quantization and transformers.
ðŸ”¹ Influenced DALLÂ·E and image tokenization.

ðŸ“Œ Citation: https://arxiv.org/abs/2012.09841

ðŸ§  2021â€“2022: Diffusion Models and Foundation Models
9. DDPM: Denoising Diffusion Probabilistic Models
Ho et al., 2020 (published 2021)
ðŸ”¹ Introduced the modern diffusion model framework.
ðŸ”¹ Key breakthrough in image synthesis, used in DALLE-2, Stable Diffusion.

ðŸ“Œ Citation: https://arxiv.org/abs/2006.11239

10. DALLÂ·E: Zero-Shot Text-to-Image Generation
OpenAI, 2021
ðŸ”¹ Introduced multimodal generation at scale (text â†’ image).
ðŸ”¹ Used discrete VAE and transformer decoder.

ðŸ“Œ Blog: https://openai.com/research/dall-e

11. Imagen: Photorealistic Text-to-Image Diffusion Models
Saharia et al., Google Research, 2022
ðŸ”¹ Achieved SOTA photorealism in text-to-image generation.
ðŸ”¹ Uses T5 encoder + cascaded diffusion decoders.

ðŸ“Œ Citation: https://arxiv.org/abs/2205.11487

12. GLIDE: Guided Language to Image Diffusion for Generation
Nichol et al., OpenAI, 2021
ðŸ”¹ Introduced CLIP guidance into diffusion models.
ðŸ”¹ Predecessor to DALLÂ·E 2.

ðŸ“Œ Citation: https://arxiv.org/abs/2112.10741

ðŸ§  2023â€“2024: LLMs, Alignment, and Agentic AI
13. GPT-4 Technical Report
OpenAI, 2023
ðŸ”¹ First multimodal foundation model (image + text).
ðŸ”¹ No architecture details, but sparked widespread real-world use.

ðŸ“Œ Citation: https://openai.com/research/gpt-4

14. PaLM-E: Embodied Multimodal Language Model
Google DeepMind, 2023
ðŸ”¹ Combines robotics, vision, and language.
ðŸ”¹ Early example of embodied and agentic generative AI.

ðŸ“Œ Citation: https://arxiv.org/abs/2303.03378

15. Self-Rewarding Language Agents
Google DeepMind, 2024
ðŸ”¹ Introduced language agents that generate their own reward signals.
ðŸ”¹ Foundation for autonomous agentic systems.

ðŸ“Œ Citation: https://arxiv.org/abs/2403.07691

16. LLM-as-a-Judge: Automatic Evaluation of Generated Content
OpenAI, Anthropic, Meta-style labs, 2023â€“2024
ðŸ”¹ Popularized use of LLMs to evaluate generative model outputs.
ðŸ”¹ Now common in RAG, alignment, safety pipelines.

ðŸ§  Bonus: Infrastructure & Training Papers
ðŸ”¸ LoRA: Low-Rank Adaptation of Large Language Models (Hu et al., 2021)
https://arxiv.org/abs/2106.09685

ðŸ”¸ RLHF: Deep RL from Human Preferences (Christiano et al., 2017)
https://arxiv.org/abs/1706.03741

ðŸ”¸ Transformer Interpretability & Scaling Laws (Kaplan et al., 2020; Anthropic 2022â€“24)
